---
title: Greedy Algorithms
createTime: 2025/06/06 11:21:13
permalink: /fit2004/gvwc31o1/
---

### Dijkstra's Algorithm

#### Edge Relaxation

:::note Edge Relaxation Process
Two pieces of information are considered for vertex $v$:

- **The distance:** We update `dist[v]` to this new, shorter distance
- **The predecessor:** We update `pred[v]` to be $u$, indicating that the best path to $v$ now comes from $u$
:::

```python
def relax(u, v, weight, distances, predecessors):
    """
    Performs the edge relaxation step.

    Args:
        u: The source vertex of the edge.
        v: The destination vertex of the edge.
        weight: The weight of the edge (u, v).
        distances: A dictionary mapping vertices to their current shortest distance
                   from the source.
        predecessors: A dictionary mapping vertices to their predecessor on the
                      shortest path.
    """
    if distances[v] > distances[u] + weight:
        # Found a shorter path to v through u
        distances[v] = distances[u] + weight
        predecessors[v] = u
        return True # Indicates that an update was made
    return False # No update was made
```

#### Implementation

:::tip Complexity Analysis
**Time complexity depends on the priority queue implementation:**

**Array Implementation:**
- Linear $O(|V|)$ time to find the next vertex
- Total running time: $O(|E| + |V|^2) = O(|V|^2)$

**Binary Heap Implementation:** 
- $O(\log|V|)$ time per priority queue operation
- Total running time: $O(|E|\log|V| + |V|\log|V|) = O(|E|\log|V|)$
:::

```python
def dijkstra_improved(graph, num_vertices, start_vertex):
    """
    Implements the improved version of Dijkstra's algorithm using a priority queue.
    This version strictly follows the provided pseudocode and avoids dicts and sets.

    Args:
        graph: A list of lists representing the adjacency list.
               graph[u] contains a list of tuples (v, weight) for each neighbor v of u.
        num_vertices: The total number of vertices in the graph (n).
        start_vertex: The integer index (0 to n-1) of the starting vertex.

    Returns:
        A tuple containing two lists: (distances, predecessors)
    """
    # We use math.inf for infinity and size the list for n vertices.
    dist = [math.inf] * num_vertices

    # We use None to indicate no predecessor.
    pred = [None] * num_vertices

    dist[start_vertex] = 0

    # We initialize a list that will be managed by the heapq module.
    # It stores tuples of (key, vertex).
    priority_queue = []

    heapq.heappush(priority_queue, (0, start_vertex))

    while priority_queue:
        # Line 8: u, key = Q.pop_min()
        key, u = heapq.heappop(priority_queue)

        # This check avoids processing out-of-date (stale) entries in the queue.
        # If we have found a shorter path to u since this entry was added,
        # key will be greater than dist[u], so we skip.
        if key == dist[u]:
            for v, weight in graph[u]:
                if dist[v] > dist[u] + weight:
                    dist[v] = dist[u] + weight
                    pred[v] = u
                    heapq.heappush(priority_queue, (dist[v], v))

    return dist, pred
```

### Minimum Spanning Tree

#### Prim's Algorithm

:::important Prim's Algorithm Overview
Prim's algorithm begins with an arbitrarily chosen source vertex and builds a tree $T$, adding edges one at a time to form a spanning tree. The edge to add at each iteration is chosen such that it is the ==lightest weight edge== that connects the current partial spanning tree $T$ to some new vertex $v$ not yet in the tree.
:::

:::note Complexity Comparison
**Similarity to Dijkstra's:** The main difference is that the key used to greedily select the next vertex $v$ is taken to be the weight of the lightest edge $w(u, v)$.

**Time Complexity:** Using a binary heap to implement the priority queue: $O(|E|\log|V|)$
:::

```python
import heapq

def prims_algorithm(graph, num_vertices, start_vertex):
    """
    Implements Prim's algorithm to find a Minimum Spanning Tree (MST).
    This version strictly follows the provided pseudocode and avoids dicts and sets.

    Args:
        graph: A list of lists representing the adjacency list.
               graph[u] contains a list of tuples (v, weight) for each neighbor v of u.
        num_vertices: The total number of vertices in the graph (n).
        start_vertex: The integer index (0 to n-1) of the starting vertex (root 'r').

    Returns:
        A tuple containing: (parent_array, total_cost)
        The parent_array can be used to reconstruct the edges of the MST.
    """
    # dist[v] stores the minimum edge weight connecting v to the MST.
    dist = [math.inf] * num_vertices

    # parent[v] stores the vertex in the MST that connects to v.
    parent = [None] * num_vertices

    # A list to track vertices already included in the MST. This replaces
    # the check 'if not v in T' from the pseudocode (Line 12).
    in_mst = [False] * num_vertices

    dist[start_vertex] = 0

    # We initialize a priority queue and push the starting vertex.
    # The queue will store tuples of (distance, vertex).
    priority_queue = [(0, start_vertex)]

    while priority_queue:
        current_dist, u = heapq.heappop(priority_queue)

        # This check handles outdated entries. If u is already in the MST,
        # we pulled a "lazy" entry from the queue, so we skip it.
        if in_mst[u]:
            continue

        # We mark the vertex as included. The edge is implicitly stored
        # in the parent array.
        in_mst[u] = True

        for v, weight in graph[u]:
            if not in_mst[v] and dist[v] > weight:
                dist[v] = weight
                parent[v] = u
                # We do this by pushing the new, improved distance for v.
                heapq.heappush(priority_queue, (dist[v], v))

    # We return the parent array, which defines the MST, and calculate its total cost.
    total_cost = sum(dist[i] for i in range(num_vertices) if dist[i] != math.inf)
    
    return parent, total_cost
```

### Kruskal’s algorithms

The implementation may not be examinable as it is using set. But the approach still examinable. So the code block would be not added for this algorithm. 

Steps to solve:

- Take the list of edges and sort.
    - Easy .. just use QuickSort → This is O(E log E)
- Check if vertex u and vertex v in <u, v, w> is in the same tree → O(1)
    - We use set! Any set data structure
        - Build-in Python Set
        - Disjoint-Set
- If not the same set, you joint them with the edges (Union) → O(V)

Complexity: $O(|E| log |E| + |E|(1+|V|)) = O(|E| \cdot |V|)$