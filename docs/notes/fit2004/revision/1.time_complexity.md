---
title: Time Complexity and Recurrence Relation
createTime: 2025/06/06 11:21:13
permalink: /fit2004/0ltwakvc/
---

### Notation for Complexity

:::info Asymptotic Notation
These notations describe the behavior of functions as input size approaches infinity.
:::

**Big-O (Upper Bound)**

$f(n) = O(g(n))$ if there are constants $c$ and $n_0$ such that $f(n) ≤ c ⋅ g(n)$, for all $n ≥ n_0$

**Big-Ω (Lower Bound)**

$f(n) = Ω(g(n))$ if there are constants $c$ and $n_0$ such that $f(n) ≥ c ⋅ g(n)$, for all $n ≥ n_0$

**Big-Θ (Tight Bound)**

$f(n) = Θ(g(n))$ if, and only if, $f(n) = O(g(n))$ and $f(n) = Ω(g(n))$

#### Summary of Recurrence Relations

| Pattern Name | Recurrence Relation Form | Common Example | Big-O Complexity |
| --- | --- | --- | --- |
| **Logarithmic** | $T(n)=T(\frac{n}{b})+O(1)$ | Binary Search | $O(\log n)$ |
| **Linearithmic** | $T(n)=aT(\frac{n}{b})+O(n)$, if $a = b$ | Merge Sort | $O(n \log n)$ |
| **Linear** | $T(n) = T(n-c)+O(1)$ | Simple loop/Recursion | $O(n)$ |
| **Quadratic** | $T(n) = T(n-1)+O(n)$ | Selection Sort | $O(n^2)$ |
| **Exponential** | $T(n) = a T(n - c)$ with $a > 1$ | Naive Fibonacci | $O(k^n)$ |

### Master Theorem

:::important Master Theorem Form
The Master Theorem applies to recurrence relations of the form: 

$$T(n) = aT\left(\frac{n}{b}\right) + f(n)$$

**Where:**
- $T(n)$: The time complexity of a problem of size $n$
- $a$: The number of subproblems in each recursive step ($a \geq 1$)
- $n/b$: The size of each subproblem ($b > 1$)
- $f(n)$: The cost of the work done outside the recursive calls (divide and combine steps)
:::

The Master Theorem is essentially a way to determine which part of a recursive algorithm dominates its runtime. It’s a battle between two forces:

- The work from the recursive calls: This represented by the term aT(n/b). The more subproblems you create, the more this force contributes.
- The work done at each level: This is represented by f(n). This is the cost of splitting the problem and merging the results.

To figure out which force wins, the Master Theorem compares f(n) with critical function $n^{log_b a}$

#### Representation of $n^{\log_b a}$

This term represents the number of leaf nodes in the recursion tree. Think of it this way: the tree has a height of log_b n, and it branches a times at each level. The total number of leaves at the bottom of the tree is $a^{log_b n}$, which can be rewritten as $n^{log_b a}$. This tern effectively captures the growth rate of the recursive part of the algorithm.

#### The Three Cases of the Master Theorem

##### Case 1: The Recursion Dominates (Leaf-Heavy)

- **Condition:** If $f(n)$ is ==polynomially smaller== than $n^{\log_b a}$, formally, $f(n) = O(n^{\log_b a-\epsilon})$ for some constant $\epsilon > 0$.
- **Result:** $T(n) = \Theta(n^{\log_b a})$
- Example: $T(n)=8T(n/2)+n^2$
    - a=8, b=2, f(n) = $n^2$
    - Calculate the critical function: $n^{\log_b a}=n^{\log_2 8}=n^3$
    - Compare: $f(n) = n^2$ is polynomially smaller than $n^3$
    - **Conclusion:** The complexity is $\Theta(n^{\log_2 8}) = \Theta(n^3)$

##### Case 2: The Work is Balanced

- **Condition:** If $f(n)$ is ==asymptotically equal== to $n^{\log_b a}$, formally, $f(n) = \Theta(n^{\log_b a})$
- **Result:** $T(n) = \Theta(n^{\log_b a} \log n)$
- Example: $T(n) = 2T(n/2) + n$ (Merge Sort)
    - Calculate the critical function: $n^{\log_b a}=n^{\log_2 2}=n^1=n$
    - Compare: $f(n)$ is asymptotically equal to $n$
    - **Conclusion:** The complexity is $\Theta(n \log n)$

##### Case 3: The Combine Step Dominates (Root-Heavy)

- **Condition:** If $f(n)$ is ==polynomially larger== than $n^{\log_b a}$, formally, $f(n) = \Omega(n^{\log_b a+\epsilon})$ for some constant $\epsilon > 0$. **AND** $a \cdot f(n/b) \leq c \cdot f(n)$ for some constant $c < 1$ and all sufficiently large $n$.
- **Result:** $T(n) = \Theta(f(n))$
- Example: $T(n)=3T(n/4)+n^2$
    - Calculate the critical function: $n^{\log_b a}=n^{\log_4 3}\approx n^{0.79}$
    - Compare: $f(n) = n^2$ is polynomially larger than $n^{0.79}$
    - Check regularity condition: $3 \cdot (n/4)^2 \leq c \cdot n^2$ for some $c < 1$?
        - The condition holds
    - **Conclusion:** The complexity is $\Theta(f(n)) = \Theta(n^2)$

#### Summary of the Master Theorem

| Case | Condition for $f(n)$ vs. $n^{log_b a}$ | Resulting Complexity | Intuition |
| --- | --- | --- | --- |
| 1 | $f(n)$ is polynomially smaller | $Θ(n^{log_b a})$ | Leaf-heavy: Recursion dominates. |
| 2 | $f(n)$ is asymptotically equal | $Θ(n^{log_b a} log n)$ | Balanced: Work is even across levels. |
| 3 | $f(n)$ is polynomially larger (and regularity condition holds) | $Θ(f(n))$ | Root-heavy: Combine step dominates. |
